{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3d1e595",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-07T22:41:55.800044Z",
     "iopub.status.busy": "2025-04-07T22:41:55.799767Z",
     "iopub.status.idle": "2025-04-07T22:42:33.831106Z",
     "shell.execute_reply": "2025-04-07T22:42:33.829956Z"
    },
    "papermill": {
     "duration": 38.037256,
     "end_time": "2025-04-07T22:42:33.832821",
     "exception": false,
     "start_time": "2025-04-07T22:41:55.795565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.9/452.9 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Configuration\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "from IPython.display import Markdown, display\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load configuration\n",
    "CONFIG_PATH = 'config.yaml'  # Create this file with your configurations\n",
    "try:\n",
    "    with open(CONFIG_PATH) as f:\n",
    "        config = yaml.safe_load(f)\n",
    "except FileNotFoundError:\n",
    "    logger.warning(\"Config file not found. Using default configuration.\")\n",
    "    config = {\n",
    "        'max_articles_per_source': 5,\n",
    "        'request_timeout': 10,\n",
    "        'embedding_dimension': 768,\n",
    "        'cache_dir': './cache',\n",
    "        'database_path': './vectordb'\n",
    "    }\n",
    "\n",
    "# Install and import required packages\n",
    "def setup_environment():\n",
    "    try:\n",
    "        !pip install -q \"google-generativeai>=0.3.1\" \"chromadb>=0.6.3\" \"requests\" \\\n",
    "            \"beautifulsoup4\" \"lxml[html_clean]\" \"newspaper3k\" \"pyyaml\" \"tqdm\"\n",
    "        logger.info(\"Packages installed successfully\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error installing packages: {e}\")\n",
    "        raise\n",
    "\n",
    "# Initialize API and models\n",
    "def initialize_models():\n",
    "    try:\n",
    "        import google.generativeai as genai\n",
    "        from kaggle_secrets import UserSecretsClient\n",
    "        \n",
    "        # Get API key securely\n",
    "        GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "        genai.configure(api_key=GOOGLE_API_KEY)\n",
    "        \n",
    "        # Find available models\n",
    "        models = genai.list_models()\n",
    "        text_model = next((m.name for m in models if \"gemini-pro\" in m.name.lower()), \"gemini-1.0-pro\")\n",
    "        embedding_model = next((m.name for m in models if \"embedding\" in m.name.lower()), \"embedding-001\")\n",
    "        \n",
    "        # Model configurations\n",
    "        generation_config = {\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_p\": 0.95,\n",
    "            \"top_k\": 40,\n",
    "            \"max_output_tokens\": 1024,\n",
    "        }\n",
    "        \n",
    "        safety_settings = [\n",
    "            {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
    "            {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
    "            {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
    "            {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
    "        ]\n",
    "        \n",
    "        generation_model = genai.GenerativeModel(\n",
    "            model_name=text_model,\n",
    "            generation_config=generation_config,\n",
    "            safety_settings=safety_settings\n",
    "        )\n",
    "        \n",
    "        return generation_model, embedding_model\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error initializing models: {e}\")\n",
    "        raise\n",
    "\n",
    "# Setup cache directory\n",
    "os.makedirs(config['cache_dir'], exist_ok=True)\n",
    "\n",
    "# Run setup\n",
    "setup_environment()\n",
    "generation_model, embedding_model = initialize_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5459dfb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:42:33.842807Z",
     "iopub.status.busy": "2025-04-07T22:42:33.842310Z",
     "iopub.status.idle": "2025-04-07T22:42:46.442310Z",
     "shell.execute_reply": "2025-04-07T22:42:46.441181Z"
    },
    "papermill": {
     "duration": 12.606246,
     "end_time": "2025-04-07T22:42:46.443659",
     "exception": false,
     "start_time": "2025-04-07T22:42:33.837413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching news: 100%|██████████| 4/4 [00:12<00:00,  3.14s/it]\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Enhanced News Fetching with Caching\n",
    "\n",
    "class NewsFetcher:\n",
    "    def __init__(self, cache_dir: str, timeout: int = 10):\n",
    "        self.cache_dir = cache_dir\n",
    "        self.timeout = timeout\n",
    "        self.cache_file = os.path.join(cache_dir, 'news_cache.json')\n",
    "        self.rss_feeds = {\n",
    "            'technology': [\n",
    "                'https://feeds.feedburner.com/TechCrunch/',\n",
    "                'https://www.wired.com/feed/rss',\n",
    "            ],\n",
    "            'business': [\n",
    "                'https://feeds.marketwatch.com/marketwatch/topstories/',\n",
    "                'https://www.forbes.com/business/feed/',\n",
    "            ],\n",
    "            'science': [\n",
    "                'https://rss.nytimes.com/services/xml/rss/nyt/Science.xml',\n",
    "                'https://www.sciencedaily.com/rss/all.xml',\n",
    "            ],\n",
    "            'health': [\n",
    "                'https://rss.nytimes.com/services/xml/rss/nyt/Health.xml',\n",
    "                'https://www.who.int/rss-feeds/news-english.xml',\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "    def load_cache(self) -> Dict:\n",
    "        try:\n",
    "            if os.path.exists(self.cache_file):\n",
    "                with open(self.cache_file, 'r') as f:\n",
    "                    return json.load(f)\n",
    "            return {}\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading cache: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def save_cache(self, cache_data: Dict):\n",
    "        try:\n",
    "            with open(self.cache_file, 'w') as f:\n",
    "                json.dump(cache_data, f)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving cache: {e}\")\n",
    "\n",
    "    def fetch_article_content(self, url: str) -> str:\n",
    "        try:\n",
    "            from newspaper import Article\n",
    "            article = Article(url)\n",
    "            article.download()\n",
    "            article.parse()\n",
    "            return article.text\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error using newspaper3k: {e}\")\n",
    "            try:\n",
    "                response = requests.get(url, timeout=self.timeout)\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                paragraphs = soup.find_all('p')\n",
    "                return ' '.join([p.text for p in paragraphs])\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error fetching article content: {e}\")\n",
    "                return \"\"\n",
    "\n",
    "    def fetch_news(self, max_articles_per_category: int = 5) -> List[Dict]:\n",
    "        cache = self.load_cache()\n",
    "        current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        if current_date in cache:\n",
    "            logger.info(\"Using cached news data\")\n",
    "            return cache[current_date]\n",
    "        \n",
    "        all_articles = []\n",
    "        \n",
    "        for category, feeds in tqdm(self.rss_feeds.items(), desc=\"Fetching news\"):\n",
    "            articles_count = 0\n",
    "            for feed_url in feeds:\n",
    "                if articles_count >= max_articles_per_category:\n",
    "                    break\n",
    "                    \n",
    "                try:\n",
    "                    response = requests.get(feed_url, timeout=self.timeout)\n",
    "                    soup = BeautifulSoup(response.content, features=\"xml\")\n",
    "                    items = soup.findAll('item')\n",
    "                    \n",
    "                    for item in items:\n",
    "                        if articles_count >= max_articles_per_category:\n",
    "                            break\n",
    "                            \n",
    "                        title = item.find('title').text\n",
    "                        link = item.find('link').text\n",
    "                        content = self.fetch_article_content(link)\n",
    "                        \n",
    "                        if content:\n",
    "                            all_articles.append({\n",
    "                                'title': title,\n",
    "                                'link': link,\n",
    "                                'content': content,\n",
    "                                'category': category,\n",
    "                                'date': current_date\n",
    "                            })\n",
    "                            articles_count += 1\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error fetching from {feed_url}: {e}\")\n",
    "                    continue\n",
    "                    \n",
    "                time.sleep(1)  # Rate limiting\n",
    "        \n",
    "        # Update cache\n",
    "        cache[current_date] = all_articles\n",
    "        self.save_cache(cache)\n",
    "        \n",
    "        return all_articles\n",
    "\n",
    "# Initialize fetcher and get news\n",
    "news_fetcher = NewsFetcher(config['cache_dir'])\n",
    "all_articles = news_fetcher.fetch_news(max_articles_per_category=config['max_articles_per_source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89f7e92b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:42:46.453745Z",
     "iopub.status.busy": "2025-04-07T22:42:46.453442Z",
     "iopub.status.idle": "2025-04-07T22:42:49.746525Z",
     "shell.execute_reply": "2025-04-07T22:42:49.745140Z"
    },
    "papermill": {
     "duration": 3.299659,
     "end_time": "2025-04-07T22:42:49.747789",
     "exception": false,
     "start_time": "2025-04-07T22:42:46.448130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating summaries: 100%|██████████| 15/15 [00:03<00:00,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Summaries:\n",
      "\n",
      "Title: Top 10 AI Tools That Will Transform Your Content Creation in 2025\n",
      "Summary: Top 10 AI Tools That Will Transform Your Content Creation in 2025\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Looking to level up your content creation game in 2025? You're in the right place! The digital landscape has evolved dramatically, and AI tools have become essential for creators who want to stay ahead of the curve.  In this guide, I'll show you the top 10 AI tools that are revolutionizing content creation and making creators' lives easier. \n",
      "\n",
      "Why You Need These AI Tools in 2025\n",
      "\n",
      "Content creation has become more demanding than ever...\n",
      "\n",
      "Title: LimeWire AI Studio Review 2023: Details, Pricing & Features\n",
      "Summary: In the rapidly advancing landscape of AI technology and innovation, LimeWire emerges as a unique platform in the realm of generative AI tools.  This platform not only stands out from the multitude of existing AI tools but also brings a fresh approach to content generation.  LimeWire not only empowers users to create AI content but also provides creators with creative ways to share and monetize their creations...\n",
      "\n",
      "Title: Top 10 AI Tools in 2023 That Will Make Your Life Easier\n",
      "Summary: Top 10 AI Tools in 2023 That Will Make Your Life Easier\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "In this article, we explore the top 10 AI tools that are driving innovation and efficiency in various industries.  These tools are designed to automate repetitive tasks, improve workflow, and increase productivity.  The tools included in our list are some of the most advanced and widely used in the market, and are suitable for a variety of applications...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Enhanced Summarization with Few-shot Learning\n",
    "\n",
    "class NewsSummarizer:\n",
    "    def __init__(self, model, cache_dir: str):\n",
    "        self.model = model\n",
    "        self.cache_dir = cache_dir\n",
    "        self.cache_file = os.path.join(cache_dir, 'summary_cache.json')\n",
    "        \n",
    "        # Load few-shot examples\n",
    "        self.few_shot_examples = [\n",
    "            {\n",
    "                \"article\": \"The European Union has approved a new directive aimed at reducing single-use plastics...\",\n",
    "                \"summary\": \"EU bans single-use plastics by 2021 and mandates 90% recycling of plastic bottles by 2029.\"\n",
    "            },\n",
    "            {\n",
    "                \"article\": \"Researchers at Stanford University have developed a new artificial intelligence system...\",\n",
    "                \"summary\": \"Stanford AI system diagnoses pneumonia from X-rays with 95% accuracy, outperforming human radiologists.\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "    def load_cache(self) -> Dict:\n",
    "        try:\n",
    "            if os.path.exists(self.cache_file):\n",
    "                with open(self.cache_file, 'r') as f:\n",
    "                    return json.load(f)\n",
    "            return {}\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading summary cache: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def save_cache(self, cache_data: Dict):\n",
    "        try:\n",
    "            with open(self.cache_file, 'w') as f:\n",
    "                json.dump(cache_data, f)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving summary cache: {e}\")\n",
    "\n",
    "    def create_few_shot_prompt(self, article_content: str) -> str:\n",
    "        prompt = \"Generate a concise, informative summary of the following news article:\\n\\n\"\n",
    "        \n",
    "        # Add few-shot examples\n",
    "        for example in self.few_shot_examples:\n",
    "            prompt += f\"Article: {example['article']}\\n\"\n",
    "            prompt += f\"Summary: {example['summary']}\\n\\n\"\n",
    "        \n",
    "        # Add target article\n",
    "        prompt += f\"Article: {article_content}\\nSummary:\"\n",
    "        \n",
    "        return prompt\n",
    "\n",
    "    def summarize_article(self, article_content: str, max_length: int = 150) -> str:\n",
    "        # Check cache first\n",
    "        cache = self.load_cache()\n",
    "        content_hash = hash(article_content)\n",
    "        \n",
    "        if str(content_hash) in cache:\n",
    "            return cache[str(content_hash)]\n",
    "        \n",
    "        try:\n",
    "            prompt = self.create_few_shot_prompt(article_content[:5000])  # Truncate if too long\n",
    "            response = self.model.generate_content(prompt)\n",
    "            summary = response.text.strip()\n",
    "            \n",
    "            # Ensure summary length\n",
    "            if len(summary) > max_length:\n",
    "                summary = summary[:max_length].rsplit(' ', 1)[0] + '...'\n",
    "            \n",
    "            # Cache the result\n",
    "            cache[str(content_hash)] = summary\n",
    "            self.save_cache(cache)\n",
    "            \n",
    "            return summary\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating summary: {e}\")\n",
    "            # Fallback to extractive summary\n",
    "            sentences = article_content.split('.')[:3]\n",
    "            return '. '.join(sentences) + '...'\n",
    "\n",
    "# Initialize summarizer and process articles\n",
    "summarizer = NewsSummarizer(generation_model, config['cache_dir'])\n",
    "\n",
    "for article in tqdm(all_articles, desc=\"Generating summaries\"):\n",
    "    article['summary'] = summarizer.summarize_article(article['content'])\n",
    "\n",
    "# Display sample results\n",
    "print(\"\\nSample Summaries:\")\n",
    "for article in all_articles[:3]:\n",
    "    print(f\"\\nTitle: {article['title']}\")\n",
    "    print(f\"Summary: {article['summary']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a64ed7c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:42:49.759871Z",
     "iopub.status.busy": "2025-04-07T22:42:49.759548Z",
     "iopub.status.idle": "2025-04-07T22:42:49.901701Z",
     "shell.execute_reply": "2025-04-07T22:42:49.900887Z"
    },
    "papermill": {
     "duration": 0.149822,
     "end_time": "2025-04-07T22:42:49.903207",
     "exception": false,
     "start_time": "2025-04-07T22:42:49.753385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 123.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity Analysis:\n",
      "\n",
      "Finding similar articles for: Top 10 AI Tools That Will Transform Your Content Creation in 2025\n",
      "- Top 10 AI Content Generator & Writer Tools in 2022 (Similarity: 0.0837)\n",
      "- The Very Territorial Caterpillar (Similarity: 0.0733)\n",
      "\n",
      "Finding similar articles for: LimeWire AI Studio Review 2023: Details, Pricing & Features\n",
      "- Top 10 AI Tools That Will Transform Your Content Creation in 2025 (Similarity: 0.0548)\n",
      "- Why Cameras Are Popping Up in Eldercare Facilities (Similarity: 0.0395)\n",
      "\n",
      "Finding similar articles for: Top 10 AI Tools in 2023 That Will Make Your Life Easier\n",
      "- As RFK Jr. Champions Chronic Disease Prevention, Key Research Is Cut (Similarity: 0.0355)\n",
      "- An Endangered Galápagos Tortoise Is a First-Time Mother at 100 (Similarity: 0.0302)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Enhanced Embeddings System\n",
    "\n",
    "class ArticleEmbedder:\n",
    "    def __init__(self, model_name: str, cache_dir: str, dimension: int = 768):\n",
    "        self.model_name = model_name\n",
    "        self.cache_dir = cache_dir\n",
    "        self.dimension = dimension\n",
    "        self.cache_file = os.path.join(cache_dir, 'embedding_cache.json')\n",
    "        \n",
    "    def load_cache(self) -> Dict:\n",
    "        try:\n",
    "            if os.path.exists(self.cache_file):\n",
    "                with open(self.cache_file, 'r') as f:\n",
    "                    cache = json.load(f)\n",
    "                    # Convert string lists back to numpy arrays\n",
    "                    return {k: np.array(v) for k, v in cache.items()}\n",
    "            return {}\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading embedding cache: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def save_cache(self, cache_data: Dict):\n",
    "        try:\n",
    "            # Convert numpy arrays to lists for JSON serialization\n",
    "            serializable_cache = {k: v.tolist() for k, v in cache_data.items()}\n",
    "            with open(self.cache_file, 'w') as f:\n",
    "                json.dump(serializable_cache, f)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving embedding cache: {e}\")\n",
    "\n",
    "    def generate_embedding(self, text: str) -> np.ndarray:\n",
    "        try:\n",
    "            import google.generativeai as genai\n",
    "            embedding_model = genai.GenerativeModel(self.model_name)\n",
    "            result = embedding_model.embed_content(text=text)\n",
    "            return np.array(result.embedding)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating embedding: {e}\")\n",
    "            return np.random.randn(self.dimension)\n",
    "\n",
    "    def get_embedding(self, text: str) -> np.ndarray:\n",
    "        cache = self.load_cache()\n",
    "        text_hash = hash(text)\n",
    "        \n",
    "        if str(text_hash) in cache:\n",
    "            return cache[str(text_hash)]\n",
    "        \n",
    "        embedding = self.generate_embedding(text)\n",
    "        cache[str(text_hash)] = embedding\n",
    "        self.save_cache(cache)\n",
    "        \n",
    "        return embedding\n",
    "\n",
    "    def find_similar_articles(self, target_embedding: np.ndarray, embeddings: List[np.ndarray], \n",
    "                            top_n: int = 3) -> List[tuple]:\n",
    "        similarities = []\n",
    "        \n",
    "        for i, embedding in enumerate(embeddings):\n",
    "            similarity = np.dot(target_embedding, embedding) / (\n",
    "                np.linalg.norm(target_embedding) * np.linalg.norm(embedding)\n",
    "            )\n",
    "            similarities.append((i, similarity))\n",
    "        \n",
    "        return sorted(similarities, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "# Initialize embedder and process articles\n",
    "embedder = ArticleEmbedder(embedding_model, config['cache_dir'])\n",
    "\n",
    "# Generate embeddings for all articles\n",
    "print(\"Generating embeddings...\")\n",
    "for article in tqdm(all_articles):\n",
    "    combined_text = f\"{article['title']} {article['summary']}\"\n",
    "    article['embedding'] = embedder.get_embedding(combined_text)\n",
    "\n",
    "# Demonstrate similarity search\n",
    "print(\"\\nSimilarity Analysis:\")\n",
    "for i, article in enumerate(all_articles[:3]):\n",
    "    print(f\"\\nFinding similar articles for: {article['title']}\")\n",
    "    embeddings = [a['embedding'] for a in all_articles]\n",
    "    similar_indices = embedder.find_similar_articles(article['embedding'], embeddings)\n",
    "    \n",
    "    for idx, score in similar_indices:\n",
    "        if idx != i:  # Skip the article itself\n",
    "            print(f\"- {all_articles[idx]['title']} (Similarity: {score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "269b800c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:42:49.915600Z",
     "iopub.status.busy": "2025-04-07T22:42:49.915238Z",
     "iopub.status.idle": "2025-04-07T22:42:51.211553Z",
     "shell.execute_reply": "2025-04-07T22:42:51.210292Z"
    },
    "papermill": {
     "duration": 1.304345,
     "end_time": "2025-04-07T22:42:51.213126",
     "exception": false,
     "start_time": "2025-04-07T22:42:49.908781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Personalized Recommendations Demo:\n",
      "\n",
      "Recommendations for tech_enthusiast:\n",
      "- Top 10 AI Content Generator & Writer Tools in 2022 (technology) - Relevance: -1443.1567\n",
      "- Kennedy Attends Funeral of Texas Girl Who Died of Measles (health) - Relevance: -1473.2455\n",
      "- Top 10 AI Tools That Will Transform Your Content Creation in 2025 (technology) - Relevance: -1479.2073\n",
      "- Giant Sloths’ Hairy Truth Revealed by Scientists (science) - Relevance: -1484.0428\n",
      "- Scientists Revive the Dire Wolf, or Something Close (science) - Relevance: -1495.2771\n",
      "\n",
      "Recommendations for health_conscious:\n",
      "- Kennedy Kicks Off Tour on Fighting Chronic Disease (health) - Relevance: -1409.4835\n",
      "- Why Cameras Are Popping Up in Eldercare Facilities (health) - Relevance: -1436.9148\n",
      "- Top 10 AI Tools in 2023 That Will Make Your Life Easier (technology) - Relevance: -1454.4076\n",
      "- Giant Sloths’ Hairy Truth Revealed by Scientists (science) - Relevance: -1461.7936\n",
      "- Top 10 AI Tools That Will Transform Your Content Creation in 2025 (technology) - Relevance: -1465.6924\n",
      "\n",
      "Recommendations for business_analyst:\n",
      "- Why Cameras Are Popping Up in Eldercare Facilities (health) - Relevance: -1466.2333\n",
      "- An Endangered Galápagos Tortoise Is a First-Time Mother at 100 (science) - Relevance: -1474.4119\n",
      "- Giant Sloths’ Hairy Truth Revealed by Scientists (science) - Relevance: -1487.2981\n",
      "- LimeWire AI Studio Review 2023: Details, Pricing & Features (technology) - Relevance: -1487.6080\n",
      "- Top 10 AI Tools That Will Transform Your Content Creation in 2025 (technology) - Relevance: -1490.2512\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Enhanced RAG System with ChromaDB\n",
    "\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from chromadb.utils import embedding_functions\n",
    "import shutil\n",
    "\n",
    "class NewsRAGSystem:\n",
    "    def __init__(self, database_path: str):\n",
    "        self.database_path = database_path\n",
    "        \n",
    "        # Clean up existing database if it exists\n",
    "        if os.path.exists(database_path):\n",
    "            try:\n",
    "                shutil.rmtree(database_path)\n",
    "                logger.info(f\"Cleaned up existing database at {database_path}\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Could not clean up existing database: {e}\")\n",
    "\n",
    "        # Create fresh database directory\n",
    "        os.makedirs(database_path, exist_ok=True)\n",
    "\n",
    "        try:\n",
    "            self.client = chromadb.Client(Settings(\n",
    "                chroma_db_impl=\"duckdb+parquet\",\n",
    "                persist_directory=database_path,\n",
    "                anonymized_telemetry=False  # Disable telemetry\n",
    "            ))\n",
    "            logger.info(\"Successfully initialized ChromaDB client\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error initializing ChromaDB client: {e}\")\n",
    "            # Fallback to in-memory client\n",
    "            self.client = chromadb.Client()\n",
    "            logger.info(\"Falling back to in-memory ChromaDB client\")\n",
    "\n",
    "        self.collection_name = \"news_articles\"\n",
    "        self.setup_collection()\n",
    "        \n",
    "    def setup_collection(self):\n",
    "        try:\n",
    "            # Delete existing collection if it exists\n",
    "            try:\n",
    "                self.client.delete_collection(self.collection_name)\n",
    "                logger.info(f\"Deleted existing collection: {self.collection_name}\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # Create new collection\n",
    "            self.collection = self.client.create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\"description\": \"News articles collection\"}\n",
    "            )\n",
    "            logger.info(f\"Created new collection: {self.collection_name}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error setting up ChromaDB collection: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_articles(self, articles: List[Dict]):\n",
    "        try:\n",
    "            # Prepare data for insertion\n",
    "            ids = [str(i) for i in range(len(articles))]\n",
    "            embeddings = [article['embedding'].tolist() for article in articles]\n",
    "            metadatas = [{\n",
    "                \"title\": article['title'],\n",
    "                \"category\": article['category'],\n",
    "                \"date\": article['date']\n",
    "            } for article in articles]\n",
    "            documents = [article['content'] for article in articles]\n",
    "            \n",
    "            # Add to collection in batches\n",
    "            batch_size = 100\n",
    "            for i in range(0, len(articles), batch_size):\n",
    "                batch_end = min(i + batch_size, len(articles))\n",
    "                self.collection.add(\n",
    "                    ids=ids[i:batch_end],\n",
    "                    embeddings=embeddings[i:batch_end],\n",
    "                    metadatas=metadatas[i:batch_end],\n",
    "                    documents=documents[i:batch_end]\n",
    "                )\n",
    "            logger.info(f\"Added {len(articles)} articles to the collection\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error adding articles to ChromaDB: {e}\")\n",
    "            raise\n",
    "\n",
    "    def get_personalized_recommendations(self, \n",
    "                                       user_preferences: List[str], \n",
    "                                       num_results: int = 5) -> List[Dict]:\n",
    "        try:\n",
    "            # Generate embedding for user preferences\n",
    "            query = \" \".join(user_preferences)\n",
    "            query_embedding = embedder.get_embedding(query)\n",
    "            \n",
    "            # Query the collection\n",
    "            results = self.collection.query(\n",
    "                query_embeddings=[query_embedding.tolist()],\n",
    "                n_results=min(num_results, self.collection.count()),\n",
    "                include=[\"metadatas\", \"documents\", \"distances\"]\n",
    "            )\n",
    "            \n",
    "            # Format results\n",
    "            recommendations = []\n",
    "            for i in range(len(results['ids'][0])):\n",
    "                recommendations.append({\n",
    "                    \"title\": results['metadatas'][0][i]['title'],\n",
    "                    \"category\": results['metadatas'][0][i]['category'],\n",
    "                    \"content\": results['documents'][0][i],\n",
    "                    \"relevance_score\": 1 - results['distances'][0][i]  # Convert distance to similarity\n",
    "                })\n",
    "            \n",
    "            return recommendations\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error getting recommendations: {e}\")\n",
    "            return []\n",
    "\n",
    "# Ensure database directory exists in config\n",
    "if 'database_path' not in config:\n",
    "    config['database_path'] = os.path.join(config['cache_dir'], 'chromadb')\n",
    "\n",
    "# Initialize RAG system\n",
    "try:\n",
    "    rag_system = NewsRAGSystem(config['database_path'])\n",
    "    \n",
    "    # Add articles to the system\n",
    "    rag_system.add_articles(all_articles)\n",
    "    \n",
    "    # Demonstrate personalized recommendations\n",
    "    user_profiles = {\n",
    "        \"tech_enthusiast\": [\"artificial intelligence\", \"software development\", \"tech startups\"],\n",
    "        \"health_conscious\": [\"medical research\", \"healthcare innovation\", \"wellness\"],\n",
    "        \"business_analyst\": [\"market trends\", \"economic policy\", \"business strategy\"]\n",
    "    }\n",
    "\n",
    "    print(\"\\nPersonalized Recommendations Demo:\")\n",
    "    for profile, interests in user_profiles.items():\n",
    "        print(f\"\\nRecommendations for {profile}:\")\n",
    "        recommendations = rag_system.get_personalized_recommendations(interests)\n",
    "        for rec in recommendations:\n",
    "            print(f\"- {rec['title']} ({rec['category']}) - Relevance: {rec['relevance_score']:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error in RAG system setup: {e}\")\n",
    "    print(\"Failed to initialize RAG system. Please check the logs for details.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e3ade61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:42:51.225907Z",
     "iopub.status.busy": "2025-04-07T22:42:51.225553Z",
     "iopub.status.idle": "2025-04-07T22:42:51.273821Z",
     "shell.execute_reply": "2025-04-07T22:42:51.272405Z"
    },
    "papermill": {
     "duration": 0.056844,
     "end_time": "2025-04-07T22:42:51.275743",
     "exception": false,
     "start_time": "2025-04-07T22:42:51.218899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dashboard for tech_enthusiast\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin: 20px 0;\">\n",
       "            <h3>Trending Topics</h3>\n",
       "            <div style=\"display: flex; flex-wrap: wrap;\">\n",
       "        \n",
       "                <span style=\"background: #f0f0f0; padding: 5px 10px; margin: 5px; \n",
       "                border-radius: 15px;\">that (17)</span>\n",
       "                \n",
       "                <span style=\"background: #f0f0f0; padding: 5px 10px; margin: 5px; \n",
       "                border-radius: 15px;\">tools (15)</span>\n",
       "                \n",
       "                <span style=\"background: #f0f0f0; padding: 5px 10px; margin: 5px; \n",
       "                border-radius: 15px;\">content (13)</span>\n",
       "                </div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <h2>Your Personalized News Feed</h2>\n",
       "        <p>Based on interests: artificial intelligence, software development, tech startups</p>\n",
       "        \n",
       "        <div style=\"border: 1px solid #ddd; padding: 15px; margin: 10px 0; border-radius: 5px;\">\n",
       "            <h3>Top 10 AI Content Generator & Writer Tools in 2022</h3>\n",
       "            <p><strong>Category:</strong> technology<br>Relevance Score: -1443.1567</p>\n",
       "            <p></p>\n",
       "            <a href=\"#\" target=\"_blank\">Read more</a>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"border: 1px solid #ddd; padding: 15px; margin: 10px 0; border-radius: 5px;\">\n",
       "            <h3>Kennedy Attends Funeral of Texas Girl Who Died of Measles</h3>\n",
       "            <p><strong>Category:</strong> health<br>Relevance Score: -1473.2455</p>\n",
       "            <p></p>\n",
       "            <a href=\"#\" target=\"_blank\">Read more</a>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"border: 1px solid #ddd; padding: 15px; margin: 10px 0; border-radius: 5px;\">\n",
       "            <h3>Top 10 AI Tools That Will Transform Your Content Creation in 2025</h3>\n",
       "            <p><strong>Category:</strong> technology<br>Relevance Score: -1479.2073</p>\n",
       "            <p></p>\n",
       "            <a href=\"#\" target=\"_blank\">Read more</a>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"border: 1px solid #ddd; padding: 15px; margin: 10px 0; border-radius: 5px;\">\n",
       "            <h3>Giant Sloths’ Hairy Truth Revealed by Scientists</h3>\n",
       "            <p><strong>Category:</strong> science<br>Relevance Score: -1484.0428</p>\n",
       "            <p></p>\n",
       "            <a href=\"#\" target=\"_blank\">Read more</a>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"border: 1px solid #ddd; padding: 15px; margin: 10px 0; border-radius: 5px;\">\n",
       "            <h3>Scientists Revive the Dire Wolf, or Something Close</h3>\n",
       "            <p><strong>Category:</strong> science<br>Relevance Score: -1495.2771</p>\n",
       "            <p></p>\n",
       "            <a href=\"#\" target=\"_blank\">Read more</a>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dashboard for health_conscious\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin: 20px 0;\">\n",
       "            <h3>Trending Topics</h3>\n",
       "            <div style=\"display: flex; flex-wrap: wrap;\">\n",
       "        \n",
       "                <span style=\"background: #f0f0f0; padding: 5px 10px; margin: 5px; \n",
       "                border-radius: 15px;\">that (17)</span>\n",
       "                \n",
       "                <span style=\"background: #f0f0f0; padding: 5px 10px; margin: 5px; \n",
       "                border-radius: 15px;\">tools (15)</span>\n",
       "                \n",
       "                <span style=\"background: #f0f0f0; padding: 5px 10px; margin: 5px; \n",
       "                border-radius: 15px;\">content (13)</span>\n",
       "                </div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <h2>Your Personalized News Feed</h2>\n",
       "        <p>Based on interests: medical research, healthcare innovation, wellness</p>\n",
       "        \n",
       "        <div style=\"border: 1px solid #ddd; padding: 15px; margin: 10px 0; border-radius: 5px;\">\n",
       "            <h3>Kennedy Kicks Off Tour on Fighting Chronic Disease</h3>\n",
       "            <p><strong>Category:</strong> health<br>Relevance Score: -1409.4835</p>\n",
       "            <p></p>\n",
       "            <a href=\"#\" target=\"_blank\">Read more</a>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"border: 1px solid #ddd; padding: 15px; margin: 10px 0; border-radius: 5px;\">\n",
       "            <h3>Why Cameras Are Popping Up in Eldercare Facilities</h3>\n",
       "            <p><strong>Category:</strong> health<br>Relevance Score: -1436.9148</p>\n",
       "            <p></p>\n",
       "            <a href=\"#\" target=\"_blank\">Read more</a>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"border: 1px solid #ddd; padding: 15px; margin: 10px 0; border-radius: 5px;\">\n",
       "            <h3>Top 10 AI Tools in 2023 That Will Make Your Life Easier</h3>\n",
       "            <p><strong>Category:</strong> technology<br>Relevance Score: -1454.4076</p>\n",
       "            <p></p>\n",
       "            <a href=\"#\" target=\"_blank\">Read more</a>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"border: 1px solid #ddd; padding: 15px; margin: 10px 0; border-radius: 5px;\">\n",
       "            <h3>Giant Sloths’ Hairy Truth Revealed by Scientists</h3>\n",
       "            <p><strong>Category:</strong> science<br>Relevance Score: -1461.7936</p>\n",
       "            <p></p>\n",
       "            <a href=\"#\" target=\"_blank\">Read more</a>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"border: 1px solid #ddd; padding: 15px; margin: 10px 0; border-radius: 5px;\">\n",
       "            <h3>Top 10 AI Tools That Will Transform Your Content Creation in 2025</h3>\n",
       "            <p><strong>Category:</strong> technology<br>Relevance Score: -1465.6924</p>\n",
       "            <p></p>\n",
       "            <a href=\"#\" target=\"_blank\">Read more</a>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dashboard for business_analyst\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin: 20px 0;\">\n",
       "            <h3>Trending Topics</h3>\n",
       "            <div style=\"display: flex; flex-wrap: wrap;\">\n",
       "        \n",
       "                <span style=\"background: #f0f0f0; padding: 5px 10px; margin: 5px; \n",
       "                border-radius: 15px;\">that (17)</span>\n",
       "                \n",
       "                <span style=\"background: #f0f0f0; padding: 5px 10px; margin: 5px; \n",
       "                border-radius: 15px;\">tools (15)</span>\n",
       "                \n",
       "                <span style=\"background: #f0f0f0; padding: 5px 10px; margin: 5px; \n",
       "                border-radius: 15px;\">content (13)</span>\n",
       "                </div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <h2>Your Personalized News Feed</h2>\n",
       "        <p>Based on interests: market trends, economic policy, business strategy</p>\n",
       "        \n",
       "        <div style=\"border: 1px solid #ddd; padding: 15px; margin: 10px 0; border-radius: 5px;\">\n",
       "            <h3>Why Cameras Are Popping Up in Eldercare Facilities</h3>\n",
       "            <p><strong>Category:</strong> health<br>Relevance Score: -1466.2333</p>\n",
       "            <p></p>\n",
       "            <a href=\"#\" target=\"_blank\">Read more</a>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"border: 1px solid #ddd; padding: 15px; margin: 10px 0; border-radius: 5px;\">\n",
       "            <h3>An Endangered Galápagos Tortoise Is a First-Time Mother at 100</h3>\n",
       "            <p><strong>Category:</strong> science<br>Relevance Score: -1474.4119</p>\n",
       "            <p></p>\n",
       "            <a href=\"#\" target=\"_blank\">Read more</a>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"border: 1px solid #ddd; padding: 15px; margin: 10px 0; border-radius: 5px;\">\n",
       "            <h3>Giant Sloths’ Hairy Truth Revealed by Scientists</h3>\n",
       "            <p><strong>Category:</strong> science<br>Relevance Score: -1487.2981</p>\n",
       "            <p></p>\n",
       "            <a href=\"#\" target=\"_blank\">Read more</a>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"border: 1px solid #ddd; padding: 15px; margin: 10px 0; border-radius: 5px;\">\n",
       "            <h3>LimeWire AI Studio Review 2023: Details, Pricing & Features</h3>\n",
       "            <p><strong>Category:</strong> technology<br>Relevance Score: -1487.6080</p>\n",
       "            <p></p>\n",
       "            <a href=\"#\" target=\"_blank\">Read more</a>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"border: 1px solid #ddd; padding: 15px; margin: 10px 0; border-radius: 5px;\">\n",
       "            <h3>Top 10 AI Tools That Will Transform Your Content Creation in 2025</h3>\n",
       "            <p><strong>Category:</strong> technology<br>Relevance Score: -1490.2512</p>\n",
       "            <p></p>\n",
       "            <a href=\"#\" target=\"_blank\">Read more</a>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 6: Enhanced Interactive Dashboard\n",
    "\n",
    "class NewsDashboard:\n",
    "    def __init__(self, rag_system: NewsRAGSystem):\n",
    "        self.rag_system = rag_system\n",
    "        \n",
    "    def create_article_card(self, article: Dict) -> str:\n",
    "        relevance_score = article.get('relevance_score', None)\n",
    "        relevance_html = f\"<br>Relevance Score: {relevance_score:.4f}\" if relevance_score else \"\"\n",
    "        \n",
    "        return f\"\"\"\n",
    "        <div style=\"border: 1px solid #ddd; padding: 15px; margin: 10px 0; border-radius: 5px;\">\n",
    "            <h3>{article['title']}</h3>\n",
    "            <p><strong>Category:</strong> {article['category']}{relevance_html}</p>\n",
    "            <p>{article.get('summary', '')}</p>\n",
    "            <a href=\"{article.get('link', '#')}\" target=\"_blank\">Read more</a>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "    def display_personalized_feed(self, user_preferences: List[str]):\n",
    "        recommendations = self.rag_system.get_personalized_recommendations(user_preferences)\n",
    "        \n",
    "        html = f\"\"\"\n",
    "        <h2>Your Personalized News Feed</h2>\n",
    "        <p>Based on interests: {', '.join(user_preferences)}</p>\n",
    "        \"\"\"\n",
    "        \n",
    "        for article in recommendations:\n",
    "            html += self.create_article_card(article)\n",
    "            \n",
    "        display(HTML(html))\n",
    "\n",
    "    def display_trending_topics(self):\n",
    "        # Analyze frequent terms in recent articles\n",
    "        from collections import Counter\n",
    "        import re\n",
    "        \n",
    "        all_text = ' '.join([a['title'] + ' ' + a.get('summary', '') for a in all_articles])\n",
    "        words = re.findall(r'\\w+', all_text.lower())\n",
    "        common_words = Counter(words).most_common(10)\n",
    "        \n",
    "        html = \"\"\"\n",
    "        <div style=\"margin: 20px 0;\">\n",
    "            <h3>Trending Topics</h3>\n",
    "            <div style=\"display: flex; flex-wrap: wrap;\">\n",
    "        \"\"\"\n",
    "        \n",
    "        for word, count in common_words:\n",
    "            if len(word) > 3:  # Filter out short words\n",
    "                html += f\"\"\"\n",
    "                <span style=\"background: #f0f0f0; padding: 5px 10px; margin: 5px; \n",
    "                border-radius: 15px;\">{word} ({count})</span>\n",
    "                \"\"\"\n",
    "                \n",
    "        html += \"</div></div>\"\n",
    "        display(HTML(html))\n",
    "\n",
    "# Initialize and display dashboard\n",
    "from IPython.display import HTML\n",
    "dashboard = NewsDashboard(rag_system)\n",
    "\n",
    "# Display for different user profiles\n",
    "for profile, interests in user_profiles.items():\n",
    "    print(f\"\\nDashboard for {profile}\")\n",
    "    dashboard.display_trending_topics()\n",
    "    dashboard.display_personalized_feed(interests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b7ad9cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T22:42:51.291116Z",
     "iopub.status.busy": "2025-04-07T22:42:51.290748Z",
     "iopub.status.idle": "2025-04-07T22:42:52.227838Z",
     "shell.execute_reply": "2025-04-07T22:42:52.226732Z"
    },
    "papermill": {
     "duration": 0.947046,
     "end_time": "2025-04-07T22:42:52.229585",
     "exception": false,
     "start_time": "2025-04-07T22:42:51.282539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting system evaluation...\n",
      "Evaluating summaries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating recommendations...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "            # News System Evaluation Report\n",
       "\n",
       "            ## Summary Quality Analysis\n",
       "            \n",
       "### Summary 1: Top 10 AI Tools That Will Transform Your Content Creation in 2025\n",
       "Evaluation Results:\n",
       "Evaluation failed: 404 Gemini 1.0 Pro Vision has been deprecated on July 12, 2024. Consider switching to different model, for example gemini-1.5-flash.\n",
       "Timestamp: 2025-04-07T22:42:51.479424\n",
       "--------------------------------------------------\n",
       "\n",
       "### Summary 2: LimeWire AI Studio Review 2023: Details, Pricing & Features\n",
       "Evaluation Results:\n",
       "Evaluation failed: 404 Gemini 1.0 Pro Vision has been deprecated on July 12, 2024. Consider switching to different model, for example gemini-1.5-flash.\n",
       "Timestamp: 2025-04-07T22:42:51.663624\n",
       "--------------------------------------------------\n",
       "\n",
       "### Summary 3: Top 10 AI Tools in 2023 That Will Make Your Life Easier\n",
       "Evaluation Results:\n",
       "Evaluation failed: 404 Gemini 1.0 Pro Vision has been deprecated on July 12, 2024. Consider switching to different model, for example gemini-1.5-flash.\n",
       "Timestamp: 2025-04-07T22:42:51.844140\n",
       "--------------------------------------------------\n",
       "\n",
       "### Summary 4: Top 10 AI Content Generator & Writer Tools in 2022\n",
       "Evaluation Results:\n",
       "Evaluation failed: 404 Gemini 1.0 Pro Vision has been deprecated on July 12, 2024. Consider switching to different model, for example gemini-1.5-flash.\n",
       "Timestamp: 2025-04-07T22:42:52.019527\n",
       "--------------------------------------------------\n",
       "\n",
       "### Summary 5: Beginner Guide to CJ Affiliate (Commission Junction) in 2022\n",
       "Evaluation Results:\n",
       "Evaluation failed: 404 Gemini 1.0 Pro Vision has been deprecated on July 12, 2024. Consider switching to different model, for example gemini-1.5-flash.\n",
       "Timestamp: 2025-04-07T22:42:52.194431\n",
       "--------------------------------------------------\n",
       "\n",
       "## Recommendation Performance Analysis\n",
       "\n",
       "### Profile: tech_enthusiast\n",
       "- Average Relevance: -1474.99\n",
       "- Preference Coverage: 3\n",
       "- Recommendations: 5\n",
       "\n",
       "### Profile: health_conscious\n",
       "- Average Relevance: -1445.66\n",
       "- Preference Coverage: 3\n",
       "- Recommendations: 5\n",
       "\n",
       "### Profile: business_analyst\n",
       "- Average Relevance: -1481.16\n",
       "- Preference Coverage: 3\n",
       "- Recommendations: 5\n",
       "\n",
       "## System Performance Metrics\n",
       "- total_articles: 15\n",
       "- evaluation_timestamp: 2025-04-07T22:42:52.221162\n",
       "- successful_summaries: 0\n",
       "- successful_recommendations: 3\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Enhanced System Evaluation and Analytics\n",
    "\n",
    "class NewsSystemEvaluator:\n",
    "    def __init__(self, generation_model):\n",
    "        self.model = generation_model\n",
    "        self.metrics = {\n",
    "            'summary_quality': [],\n",
    "            'recommendation_relevance': [],\n",
    "            'system_performance': {}\n",
    "        }\n",
    "        \n",
    "    def evaluate_summary(self, article: Dict) -> Dict:\n",
    "        try:\n",
    "            prompt = f\"\"\"\n",
    "            Evaluate this news summary on the following criteria (score 1-10):\n",
    "            1. Accuracy: Does it capture the main points?\n",
    "            2. Conciseness: Is it appropriately brief?\n",
    "            3. Clarity: Is it easy to understand?\n",
    "\n",
    "            Original Article (excerpt): {article['content'][:500]}...\n",
    "            Summary: {article.get('summary', 'No summary available')}\n",
    "\n",
    "            Format your response as:\n",
    "            Accuracy Score: [1-10]\n",
    "            Conciseness Score: [1-10]\n",
    "            Clarity Score: [1-10]\n",
    "            Overall Score: [average]\n",
    "            Feedback: [brief feedback]\n",
    "            \"\"\"\n",
    "            \n",
    "            response = self.model.generate_content(prompt)\n",
    "            \n",
    "            return {\n",
    "                'article_title': article['title'],\n",
    "                'evaluation_text': response.text,\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'success': True\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error evaluating summary: {e}\")\n",
    "            return {\n",
    "                'article_title': article.get('title', 'Unknown'),\n",
    "                'evaluation_text': f\"Evaluation failed: {str(e)}\",\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'success': False\n",
    "            }\n",
    "\n",
    "    def evaluate_recommendations(self, user_preferences: List[str], \n",
    "                               recommendations: List[Dict]) -> Dict:\n",
    "        try:\n",
    "            relevance_scores = [rec.get('relevance_score', 0) for rec in recommendations]\n",
    "            return {\n",
    "                'average_relevance': np.mean(relevance_scores) if relevance_scores else 0,\n",
    "                'preference_coverage': len(set(user_preferences)),\n",
    "                'recommendation_count': len(recommendations),\n",
    "                'success': True\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error evaluating recommendations: {e}\")\n",
    "            return {\n",
    "                'error': str(e),\n",
    "                'success': False\n",
    "            }\n",
    "\n",
    "    def generate_report(self):\n",
    "        try:\n",
    "            # Evaluate summaries\n",
    "            print(\"Evaluating summaries...\")\n",
    "            for article in tqdm(all_articles[:5]):  # Evaluate a sample\n",
    "                evaluation = self.evaluate_summary(article)\n",
    "                self.metrics['summary_quality'].append(evaluation)\n",
    "\n",
    "            # Evaluate recommendations\n",
    "            print(\"\\nEvaluating recommendations...\")\n",
    "            for profile, interests in user_profiles.items():\n",
    "                recommendations = rag_system.get_personalized_recommendations(interests)\n",
    "                self.metrics['recommendation_relevance'].append({\n",
    "                    'profile': profile,\n",
    "                    'metrics': self.evaluate_recommendations(interests, recommendations)\n",
    "                })\n",
    "\n",
    "            # Generate report\n",
    "            report = \"\"\"\n",
    "            # News System Evaluation Report\n",
    "\n",
    "            ## Summary Quality Analysis\n",
    "            \"\"\"\n",
    "            \n",
    "            # Add summary evaluations to report\n",
    "            for i, eval_data in enumerate(self.metrics['summary_quality']):\n",
    "                report += f\"\\n### Summary {i+1}: {eval_data['article_title']}\\n\"\n",
    "                report += f\"Evaluation Results:\\n{eval_data['evaluation_text']}\\n\"\n",
    "                report += f\"Timestamp: {eval_data['timestamp']}\\n\"\n",
    "                report += \"-\" * 50 + \"\\n\"\n",
    "\n",
    "            # Add recommendation performance to report\n",
    "            report += \"\\n## Recommendation Performance Analysis\\n\"\n",
    "            for rec_eval in self.metrics['recommendation_relevance']:\n",
    "                report += f\"\\n### Profile: {rec_eval['profile']}\\n\"\n",
    "                metrics = rec_eval['metrics']\n",
    "                if metrics.get('success', False):\n",
    "                    report += f\"- Average Relevance: {metrics['average_relevance']:.2f}\\n\"\n",
    "                    report += f\"- Preference Coverage: {metrics['preference_coverage']}\\n\"\n",
    "                    report += f\"- Recommendations: {metrics['recommendation_count']}\\n\"\n",
    "                else:\n",
    "                    report += f\"- Evaluation failed: {metrics.get('error', 'Unknown error')}\\n\"\n",
    "\n",
    "            # Add system performance metrics\n",
    "            self.metrics['system_performance'] = {\n",
    "                'total_articles': len(all_articles),\n",
    "                'evaluation_timestamp': datetime.now().isoformat(),\n",
    "                'successful_summaries': sum(1 for e in self.metrics['summary_quality'] if e['success']),\n",
    "                'successful_recommendations': sum(1 for e in self.metrics['recommendation_relevance'] \n",
    "                                               if e['metrics'].get('success', False))\n",
    "            }\n",
    "\n",
    "            report += \"\\n## System Performance Metrics\\n\"\n",
    "            for key, value in self.metrics['system_performance'].items():\n",
    "                report += f\"- {key}: {value}\\n\"\n",
    "\n",
    "            # Display the report\n",
    "            display(Markdown(report))\n",
    "\n",
    "            # Save detailed metrics\n",
    "            self.save_metrics()\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating report: {e}\")\n",
    "            display(Markdown(f\"# Error Generating Report\\nAn error occurred: {str(e)}\"))\n",
    "\n",
    "    def save_metrics(self):\n",
    "        \"\"\"Save metrics to file with proper error handling\"\"\"\n",
    "        try:\n",
    "            metrics_file = os.path.join(config['cache_dir'], 'evaluation_metrics.json')\n",
    "            with open(metrics_file, 'w') as f:\n",
    "                # Convert numpy values to native Python types\n",
    "                metrics_dict = json.loads(json.dumps(self.metrics, default=str))\n",
    "                json.dump(metrics_dict, f, indent=2)\n",
    "            logger.info(f\"Metrics saved to {metrics_file}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving metrics: {e}\")\n",
    "\n",
    "# Run evaluation with proper error handling\n",
    "try:\n",
    "    print(\"Starting system evaluation...\")\n",
    "    evaluator = NewsSystemEvaluator(generation_model)\n",
    "    evaluator.generate_report()\n",
    "    print(\"Evaluation completed successfully!\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Fatal error in evaluation: {e}\")\n",
    "    print(f\"Evaluation failed: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 61.478083,
   "end_time": "2025-04-07T22:42:55.040650",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-07T22:41:53.562567",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
